# -*- coding: utf-8 -*-
"""content_based_filtering.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rwSdmWb273qf8dziPop1Ne-JXL7tyax8
"""

import pandas as pd

books = pd.read_csv(r'/content/books_cleaned.csv')

books.drop(['Unnamed: 0'], axis=1, inplace=True)

books.head()

books['Content'] = books['Book-Title'] + ' ' + books['Book-Author'] + ' ' + books['Publisher']

books = books.reindex(columns=['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Content'])

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(stop_words='english') # Create the TF-IDF objesct to use

tfidf_matrix = vectorizer.fit_transform(books['Content'])

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

def get_recommendations(isbn, k=5):

    indices = books.reset_index().set_index('ISBN') # new dataframe with isbn as index

    if isbn not in indices.index:
        return []

    idx = indices.loc[isbn]['index'] #return the index of the choosen book

    sim_scores = list(enumerate(cosine_sim[idx]))

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:k+1]

    # sorted(sim_scores, key=lambda x: x[1] هرتب حسب التشابه اللي هو x[1
    # reverse=True --> sort the similarity scores in descending order
    # [1:k+1] skip [0] refers to the book itself

    book_indices = [i[0] for i in sim_scores]  #list of indices only

    return books.iloc[book_indices]['ISBN'].tolist()

# Find books with "harry potter" in the title (case-insensitive)
harry_potter_mask = books.loc[:, "Book-Title"].str.lower().str.contains("harry potter")

# Get the ISBNs of those books
harry_potter_isbns = books[harry_potter_mask].loc[:, "ISBN"].tolist()

# Get recommendations based on the first Harry Potter book
recommended_isbns = get_recommendations(harry_potter_isbns[0])

# Show recommended book titles and their ISBNs
recommended_books_df = books[books['ISBN'].isin(recommended_isbns)].loc[:, ["Book-Title", "ISBN"]]
recommended_books_df

"""# **EVALUATION**

# 1- precision
"""

def precision_at_k(recommended, actual, k=5):
    recommended_at_k = recommended[:k]
    relevant_set = set(actual)
    correct = sum([1 for book in recommended_at_k if book in relevant_set])
    return correct / k

ratings = pd.read_csv(r'/content/ratings_cleaned.csv')

user_id = 153662
# user_id = 277427

liked_books = ratings[
    (ratings['User-ID'] == user_id) &
    (ratings['Book-Rating'] >= 7)
]['ISBN'].tolist()

input_isbn = liked_books[0]

recommended_books = get_recommendations(input_isbn, k=7)

actual_books = liked_books[1:]

Precision = precision_at_k(recommended_books, actual_books,7)

print(f"Precision = {Precision:.2f}")

"""## 2- Recall"""

def recall_at_k(recommended, actual, k=5):
    recommended_at_k = recommended[:k]
    relevant_items = set(actual)
    retrieved_relevant = len([item for item in recommended_at_k if item in relevant_items])
    return retrieved_relevant / len(relevant_items) if relevant_items else 0

recall = recall_at_k(recommended_books, actual_books, k=7)
print(f"Recall = {recall:.2f}")

"""# 3- F1-Score"""

from sklearn.metrics import f1_score

recommended = get_recommendations(input_isbn, k=80)
true_books = liked_books[1:81]

true_labels = [1 if book in true_books else 0 for book in recommended]
predicted_labels = [1 if book in recommended else 0 for book in true_books]

f1 = f1_score(true_labels, predicted_labels)
print(f"F1-Score = {f1:.2f}")

"""# **VISUALIZATION FOR EVALUATION**

# 1- Confusion Matix
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cm = confusion_matrix(true_labels, predicted_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Liked', 'Liked'])
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

"""# 2- Bar plot"""

metrics = ['Precision', 'Recall', 'F1-Score']
values = [Precision, recall, f1]

metrics = list(metrics)
values = list(values)

plt.bar(metrics, values, color=['blue', 'orange', 'green'])
plt.title('Evaluation Metrics')
plt.ylim([0, 1])
plt.ylabel('Score')
plt.show()

"""# 3- Precision-Recall Curve"""

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

precision, recall, thresholds = precision_recall_curve(true_labels, predicted_labels)

plt.plot(recall, precision, marker='.')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.show()

"""# 4- ROC Curve"""

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

fpr, tpr, thresholds = roc_curve(true_labels, predicted_labels)

plt.plot(fpr, tpr, marker='.')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()